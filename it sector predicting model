from google.colab import files
upload=files.upload()

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report,confusion_matrix
from keras import models
from keras import layers

df=pd.read_excel('데이터5.xlsx')

df_date=df.set_index('Symbol Name')

df_reset = df.drop(['Symbol Name'], axis = 1)

df

it=df['it_num'].values

it=it[3:]

df_late1=df_reset.loc[:1085,:]
df_late2=df_reset.loc[1:1086,:]
df_late3=df_reset.loc[2:1087,:]
np_late1=df_late1.values
np_late2=df_late2.values
np_late3=df_late3.values

df_late11=pd.DataFrame(np_late1,columns=['en_num1',	'in_num1',	'lux_num1',	'es_num1',	'he_num1',	'fi_num1','it_num1'	,'ut_num1'	,'tr_num1'	,'co_num1'])
df_late22=pd.DataFrame(np_late2,columns=['en_num2',	'in_num2',	'lux_num2',	'es_num2',	'he_num2',	'fi_num2','it_num2'	,'ut_num2'	,'tr_num2'	,'co_num2'])
df_late33=pd.DataFrame(np_late3,columns=['en_num3',	'in_num3',	'lux_num3',	'es_num3',	'he_num3',	'fi_num3','it_num3'	,'ut_num3'	,'tr_num3'	,'co_num3'])

df_late=pd.concat([df_late11,df_late22,df_late33],axis=1)

df_late

df_late['it']=it

#it 모델
y_it_df = df_late['it']
X_it_df= df_late.drop('it',axis=1)

X_train, X_test, y_train, y_test=train_test_split(X_it_df, y_it_df, test_size=0.2, random_state=11)
# Classifier 객체 생성
dt_clf = DecisionTreeClassifier(random_state=11)
rf_clf = RandomForestClassifier(random_state=11)
lr_clf = LogisticRegression(random_state=11)
dt_clf.fit(X_train , y_train)
dt_pred = dt_clf.predict(X_test)
print('DecisionTreeClassifier 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))
rf_clf.fit(X_train , y_train)
rf_pred = rf_clf.predict(X_test)
print('RandomForestClassifier 정확도:{0:.4f}'.format(accuracy_score(y_test, rf_pred)))
lr_clf.fit(X_train , y_train)
lr_pred = lr_clf.predict(X_test)
print('LogisticRegression 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))

#it 모델
y_it_df = df_late['it']
X_it_df= df_late.drop('it',axis=1)

X_train, X_test, y_train, y_test=train_test_split(X_it_df, y_it_df, test_size=0.2, random_state=11)

y_train.value_counts()

labels_dict = {0:10000 ,1:100 , 2: 150, 3:50, 4: 9, 5:25, 6:2, 7:9, 8:100,9:1.5,10:1}

labels_dict = {0:0 ,1:0 , 2: 1, 3:4, 4: 39, 5:10, 6:141, 7:36, 8:63,9:252,10:322}

model=models.Sequential()
model.add(layers.Dense(16,activation='relu',input_dim=X_train.shape[1]))
model.add(layers.Dense(8, activation='relu'))
model.add(layers.Dense(1,activation='sigmoid'))
print(model.summary())

model.compile(optimizer='rmsprop',
loss='binary_crossentropy', metrics=['accuracy'])
history=model.fit(X_train,y_train,epochs=50,batch_size=128,validation_split=0.3, class_weight=labels_dict)

history_dict=history.history
history_dict.keys()

acc=history.history['accuracy']
val_acc=history.history['val_accuracy']
loss=history.history['loss']
val_loss=history.history['val_loss']
epochs=range(1,len(acc)+1)


plt.plot(epochs,loss,'bo',label='Training loss')
plt.plot(epochs,val_loss,'b',label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.legend()
plt.show()

plt.plot(epochs,acc,'bo',label='Training accuracy')
plt.plot(epochs,val_acc,'b',label='Validationaccuracy')
plt.title('Training and validation Accuracy')
plt.xlabel('Epochs')
plt.legend()
plt.show()
