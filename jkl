from google.colab import files
upload=files.upload()

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report,confusion_matrix
from keras import models
from keras import layers

df=pd.read_excel('데이터5.xlsx')

df_date=df.set_index('Symbol Name')

df_reset = df.drop(['Symbol Name'], axis = 1)

df

df_reset

df_date

energy=df['en_num'].values

energy=energy[3:]

df_late1=df_reset.loc[:1085,:]
df_late2=df_reset.loc[1:1086,:]
df_late3=df_reset.loc[2:1087,:]

np_late1=df_late1.values
np_late2=df_late2.values
np_late3=df_late3.values

df_late11=pd.DataFrame(np_late1,columns=['en_num1',	'in_num1',	'lux_num1',	'es_num1',	'he_num1',	'fi_num1','it_num1'	,'ut_num1'	,'tr_num1'	,'co_num1'])
df_late22=pd.DataFrame(np_late2,columns=['en_num2',	'in_num2',	'lux_num2',	'es_num2',	'he_num2',	'fi_num2','it_num2'	,'ut_num2'	,'tr_num2'	,'co_num2'])
df_late33=pd.DataFrame(np_late3,columns=['en_num3',	'in_num3',	'lux_num3',	'es_num3',	'he_num3',	'fi_num3','it_num3'	,'ut_num3'	,'tr_num3'	,'co_num3'])

df_late=pd.concat([df_late11,df_late22,df_late33],axis=1)

df_late

df_late['energy']=energy

df_late

#에너지 모델
y_energy_df = df_late['energy']
X_energy_df= df_late.drop('energy',axis=1)

X_train, X_test, y_train, y_test=train_test_split(X_energy_df, y_energy_df, test_size=0.2, random_state=11)
# Classifier 객체 생성
dt_clf = DecisionTreeClassifier(random_state=11)
rf_clf = RandomForestClassifier(random_state=11)
lr_clf = LogisticRegression(random_state=11)
dt_clf.fit(X_train , y_train)
dt_pred = dt_clf.predict(X_test)
print('DecisionTreeClassifier 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))
rf_clf.fit(X_train , y_train)
rf_pred = rf_clf.predict(X_test)
print('RandomForestClassifier 정확도:{0:.4f}'.format(accuracy_score(y_test, rf_pred)))
lr_clf.fit(X_train , y_train)
lr_pred = lr_clf.predict(X_test)
print('LogisticRegression 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))

from sklearn.metrics import accuracy_score, precision_score , recall_score ,confusion_matrix
def get_clf_eval(y_test , pred):
  confusion = confusion_matrix( y_test, pred)
  accuracy = accuracy_score(y_test , pred)
  precision = precision_score(y_test , pred)
  recall = recall_score(y_test , pred)
  print('오차 행렬')
  print(confusion)
  print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy ,precision ,recall))

get_clf_eval(y_test, dt_pred)

from sklearn.metrics import f1_score
f1 = f1_score(y_test , dt_pred)
print('F1 스코어: {0:.4f}'.format(f1))

from sklearn.metrics import roc_curve


def roc_curve_plot(y_test , pred_proba_c1):
  fprs , tprs , thresholds = roc_curve(y_test ,pred_proba_c1)
  plt.plot(fprs , tprs, label='ROC')
  plt.plot([0, 1], [0, 1], 'k--', label='Random')
  start, end = plt.xlim()
  plt.xticks(np.round(np.arange(start, end, 0.1),2))
  plt.xlim(0,1); plt.ylim(0,1)
  plt.xlabel('FPR( 1 - Sensitivity )'); plt.ylabel('TPR( Recall )')
  plt.legend()
  plt.show()

roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1] )

y_test

dt_pred



#에너지 모델
y_energy_df = df_late['energy']
X_energy_df= df_late.drop('energy',axis=1)

X_train, X_test, y_train, y_test=train_test_split(X_energy_df, y_energy_df, test_size=0.2, random_state=11)

y_train.value_counts()




labels_dict = {0:10000 ,1:1 , 2: 2, 3: 1, 4: 3, 5: 7, 6: 20, 7: 2000, 8:2000,9:100,10:2000}

labels_dict = {0:0 ,1:234 , 2:143, 3:257, 4: 121, 5: 93, 6: 18, 7: 0, 8:0,9:2,10:0}

model=models.Sequential()
model.add(layers.Dense(16,activation='softmax',input_dim=X_train.shape[1]))
model.add(layers.Dense(8, activation='softmax'))
model.add(layers.Dense(1,activation='sigmoid'))
print(model.summary())

#loss ㄹㄹ 찾아라 

model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['accuracy'])
history=model.fit(X_train,y_train,epochs=50,batch_size=128,validation_split=0.3)

history_dict=history.history
history_dict.keys()

acc=history.history['accuracy']
val_acc=history.history['val_accuracy']
loss=history.history['loss']
val_loss=history.history['val_loss']
epochs=range(1,len(acc)+1)


plt.plot(epochs,loss,'bo',label='Training loss')
plt.plot(epochs,val_loss,'b',label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.legend()
plt.show()

plt.plot(epochs,acc,'bo',label='Training accuracy')
plt.plot(epochs,val_acc,'b',label='Validationaccuracy')
plt.title('Training and validation Accuracy')
plt.xlabel('Epochs')
plt.legend()
plt.show()

predicted_result=model.predict(X_test)
predicted_result.shape

predicted_result


predicted_target=pd.Series([1 if predicted_result[i]> 0.5 else 0 for i in range(0,predicted_result.shape[0])])
print(classification_report(y_test,predicted_target,target_names=['1','2','3','4','5','6','9']))
print(confusion_matrix(y_test,predicted_target))
