from google.colab import files
upload=files.upload()

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report,confusion_matrix
from keras import models
from keras import layers

df=pd.read_excel('데이터5.xlsx')

df_date=df.set_index('Symbol Name')

df_reset = df.drop(['Symbol Name'], axis = 1)

essentials=df['es_num'].values

essentials=essentials[1:]

df_late=df_date.iloc[:-1,:]

df_late

df_late['essentials']=essentials

#필수소비재 모델
y_essentials_df = df_late['essentials']
X_essentials_df= df_late.drop('essentials',axis=1)

X_train, X_test, y_train, y_test=train_test_split(X_essentials_df, y_essentials_df, test_size=0.2, random_state=11)
# Classifier 객체 생성
dt_clf = DecisionTreeClassifier(random_state=11)
rf_clf = RandomForestClassifier(random_state=11)
lr_clf = LogisticRegression(random_state=11)
dt_clf.fit(X_train , y_train)
dt_pred = dt_clf.predict(X_test)
print('DecisionTreeClassifier 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))
rf_clf.fit(X_train , y_train)
rf_pred = rf_clf.predict(X_test)
print('RandomForestClassifier 정확도:{0:.4f}'.format(accuracy_score(y_test, rf_pred)))
lr_clf.fit(X_train , y_train)
lr_pred = lr_clf.predict(X_test)
print('LogisticRegression 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))

#필수소비재 모델
y_essentials_df = df_late['essentials']
X_essentials_df= df_late.drop('essentials',axis=1)

X_train, X_test, y_train, y_test=train_test_split(X_essentials_df, y_essentials_df, test_size=0.2, random_state=11)

y_train.value_counts()

labels_dict = {0:10000 ,1:1 , 2: 1, 3: 1, 4: 5, 5: 5, 6: 5, 7: 20000000, 8:20000000,9:2000000,10:200000}

model=models.Sequential()
model.add(layers.Dense(16,activation='relu',input_dim=X_train.shape[1]))
model.add(layers.Dense(8, activation='relu'))
model.add(layers.Dense(1,activation='sigmoid'))
print(model.summary())

model.compile(optimizer='rmsprop',
loss='binary_crossentropy', metrics=['accuracy'])
history=model.fit(X_train,y_train,epochs=50,batch_size=128,validation_split=0.3, class_weight=labels_dict)

history_dict=history.history
history_dict.keys()

acc=history.history['accuracy']
val_acc=history.history['val_accuracy']
loss=history.history['loss']
val_loss=history.history['val_loss']
epochs=range(1,len(acc)+1)


plt.plot(epochs,loss,'bo',label='Training loss')
plt.plot(epochs,val_loss,'b',label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.legend()
plt.show()

plt.plot(epochs,acc,'bo',label='Training accuracy')
plt.plot(epochs,val_acc,'b',label='Validationaccuracy')
plt.title('Training and validation Accuracy')
plt.xlabel('Epochs')
plt.legend()
plt.show()

predicted_result=model.predict(X_test)
predicted_result.shape

predicted_result

predicted_target=pd.Series([1 if predicted_result[i]> 0.5 else 0 for i in range(0,predicted_result.shape[0])])

predicted_target



print(classification_report(y_test,predicted_target,target_names=['1','2','3','4','5','6']))
print(confusion_matrix(y_test,predicted_target))
